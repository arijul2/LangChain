{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c3e173",
   "metadata": {},
   "source": [
    "# Chapter 1: LLM Fundamentals with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82213b4",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49ca44ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' falling! The sky is falling!\" In reality, it was just a figment of a chicken\\'s imagination, but their panic caused chaos in the farmyard.\\n\\nEveryone in the barn started to panic, running all over the place without thinking, and causing a commotion. The duck quacked, the cows mooed, and the sheep bleated, all trying to find out what was going on.\\n\\nIn the midst of the chaos, the wise old owl hooted, \"Calm down, everyone! What\\'s this commotion about?\" The chicken, still flapping their wings and squawking, explained, \"The sky is falling!\"\\n\\nThe owl listened carefully, then said, \"Dear chicken, the sky is not falling. It\\'s just your imagination playing tricks. Take a deep breath and let\\'s look around.\"\\n\\nWith cautious curiosity, the animals followed the owl outside to examine the blue sky above. They saw fluffy white clouds drifting by and the sun shining brightly. \"See?\" the owl said. \"The sky is as solid as ever. Sometimes our fears can lead us to jump to conclusions.\"\\n\\nHumbled by the wise owl\\'s words, the chicken felt embarrassed. “I was so worried, I didn’t stop to think,” the chicken admitted.\\n\\nFrom that day on, the'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "model = OpenAI(model=\"gpt-4o-mini\") #can add \"temperature\" and \"max_tokens\" paramters\n",
    "model.invoke(\"The sky is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7264ce",
   "metadata": {},
   "source": [
    "### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0adfd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Armenia is Yerevan.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 14, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C5kEhO4mJePb4WNEAz1Yov9pNei3y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d549653e-4db6-4c47-8744-2a1dd6f7bfae-0', usage_metadata={'input_tokens': 14, 'output_tokens': 9, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "    \n",
    "model = ChatOpenAI()\n",
    "prompt = [HumanMessage(\"What is the capital of Armenia?\")]\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b6583f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris !!!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 35, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C5MR3xCS3XcX0SiJlO6R6oMbUKwpE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--94980f56-d13b-4cd9-9b66-06b4c03bcaf7-0', usage_metadata={'input_tokens': 35, 'output_tokens': 2, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage \n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "system_msg = SystemMessage(\n",
    "    '''You are a helpful assistant that responds to questions with three\n",
    "        exclamation marks.'''\n",
    ")\n",
    "\n",
    "human_msg = HumanMessage('What is the capital of France?')\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dfb7e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Answer the question based on the\\n    context below. If the question cannot be answered using the information\\n    provided, answer with \"I don\\'t know\".\\n\\nContext: The most recent advancements in NLP are being driven by Large\\n        Language Models (LLMs). These models outperform their smaller\\n        counterparts and have become invaluable for developers who are creating\\n        applications with NLP capabilities. Developers can tap into these\\n        models through Hugging Face\\'s `transformers` library, or by utilizing\\n        OpenAI and Cohere\\'s offerings through the `openai` and `cohere`\\n        libraries, respectively.\\nQuestion: Which model providers offer LLMs?\\nAnswer: ')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
    "    context below. If the question cannot be answered using the information\n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \"\"\")\n",
    "\n",
    "template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
    "        Language Models (LLMs). These models outperform their smaller\n",
    "        counterparts and have become invaluable for developers who are creating\n",
    "        applications with NLP capabilities. Developers can tap into these\n",
    "        models through Hugging Face's `transformers` library, or by utilizing\n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e916b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face, OpenAI, Cohere.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# both `template` and `model` can be reused many times\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
    "    context below. If the question cannot be answered using the information\n",
    "    provided, answer with \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \"\"\")\n",
    "\n",
    "model = OpenAI()\n",
    "\n",
    "# `prompt` and `completion` are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
    "        Language Models (LLMs). These models outperform their smaller\n",
    "        counterparts and have become invaluable for developers who are creating\n",
    "        applications with NLP capabilities. Developers can tap into these\n",
    "        models through Hugging Face's `transformers` library, or by utilizing\n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25b9e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='A pound of bricks and a pound of feathers weigh the same: one pound.', justification='Weight is a measure of mass, and one pound is always equal to one pound, regardless of the material. Therefore, a pound of bricks and a pound of feathers both weigh exactly one pound.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user's question along with justification for the\n",
    "    answer.'''\n",
    "    answer: str\n",
    "    '''The answer to the user's question''' \n",
    "    justification: str\n",
    "    '''Justification for the answer'''\n",
    "    \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "structured_llm.invoke(\"\"\"What weighs more, a pound of bricks or a pound\n",
    "    of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2a75df1-a37d-40cc-93da-cd9dbc60bc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser \n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"apple, banana, cherry\")\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99577497-d959-4a2e-afdf-199957672aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content='Good' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content='bye' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content='!' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content=' Have' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content=' great' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content=' day' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content='!' additional_kwargs={} response_metadata={} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'} id='run--7fd04528-2238-45e2-9999-3094257ea525'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "completion = model.invoke(\"Hi there!\")\n",
    "# Hi!\n",
    "completions = model.batch([\"Hi there!\", \"Bye!\"])\n",
    "# ['Hi!', 'See you!']\n",
    "\n",
    "for token in model.stream(\"Bye!\"):\n",
    "    print(token)\n",
    "    # Good\n",
    "    # bye\n",
    "    # !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bceb0695-3edf-4ded-ab13-90681ee6dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in October 2023, several organizations and companies offer Large Language Models (LLMs) either through APIs or as downloadable models. Here are some of the prominent model providers:\n",
      "\n",
      "1. **OpenAI**: Known for its GPT series, including GPT-3 and GPT-4, OpenAI provides access to its models via an API.\n",
      "\n",
      "2. **Google**: Google offers its language models through its Google Cloud Platform, including models like BERT and LaMDA.\n",
      "\n",
      "3. **Microsoft**: Through its partnership with OpenAI, Microsoft offers OpenAI's models via Azure OpenAI Service, and it also has its own models like Turing-NLG.\n",
      "\n",
      "4. **Meta (Facebook)**: Meta has released various models like BART and OPT (Open Pre-trained Transformer) as well as newer iterations in its LLM offerings.\n",
      "\n",
      "5. **Hugging Face**: This platform hosts a vast collection of open-source models in the Transformers library, including models from various providers like BERT, GPT-2, and others.\n",
      "\n",
      "6. **EleutherAI**: This community-driven organization has released models like GPT-Neo and GPT-J, which are designed to be open-source alternatives to OpenAI's models.\n",
      "\n",
      "7. **Cohere**: Offers LLMs focused on natural language processing tasks, providing APIs for text generation and comprehension.\n",
      "\n",
      "8. **Anthropic**: Known for its Claude family of models, Anthropic provides LLMs aimed at safety and alignment.\n",
      "\n",
      "9. **AI21 Labs**: This company has developed models like Jurassic-1, which are available through an API for various NLP tasks.\n",
      "\n",
      "10. **Alibaba**: Offers LLM capabilities through its cloud platform, including models tailored for enterprise applications.\n",
      "\n",
      "11. **NVIDIA**: Known for its advancements in AI, NVIDIA provides frameworks and models for building large language models, including its own offerings like Megatron.\n",
      "\n",
      "12. **xAI**: Founded by Elon Musk, although specific details on model offerings may vary.\n",
      "\n",
      "These organizations may offer models under different licensing agreements, and availability may differ based on usage, pricing, and access conditions. Be sure to check their official websites for the most current information on their LLM offerings.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "\n",
    "# use it\n",
    "\n",
    "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d2bee58-8046-49cd-a3aa-c63e65921b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='There' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' many' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' institutions' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' worldwide' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' offer' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Master' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Laws' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='LL' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='M' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=')' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' programs' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Some' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' well' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='-known' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' universities' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' known' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' their' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' programs' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' include' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Harvard' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' University' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' New' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' York' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' University' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' University' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' California' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Berkeley' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' University' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' London' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' University' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Oxford' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' University' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Cambridge' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' Additionally' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' many' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' other' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' universities' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' across' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' globe' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' provide' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' programs' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' special' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='izations' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' cater' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' different' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' interests' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' career' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' goals' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' It' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' advisable' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' research' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' consider' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' factors' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' such' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' as' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' program' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' structure' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' faculty' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' expertise' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' location' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' when' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' choosing' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' right' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' program' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'} id='run--8aa2e1b3-66ae-44c0-84e2-9667a86c4346'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "\n",
    "for part in chatbot.stream({\"question\": \"Which model providers offer LLMs?\"}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc589e91-698f-49da-b4e4-875a93b80b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe that most major model providers offer LLMs!!!!\n",
      "content='' additional_kwargs={} response_metadata={} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n",
      "content='Many' additional_kwargs={} response_metadata={} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n",
      "content=' prestigious' additional_kwargs={} response_metadata={} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n",
      "content=' law' additional_kwargs={} response_metadata={} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n",
      "content=' schools' additional_kwargs={} response_metadata={} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n",
      "content='!!!' additional_kwargs={} response_metadata={} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'} id='run--90732002-82fd-4d53-ba9e-b71a1fe1bc13'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You answer everything with four exclamation points\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# combine them with the | operator\n",
    "\n",
    "chatbot = template | model\n",
    "\n",
    "# use it\n",
    "\n",
    "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
    "print(response.content)\n",
    "\n",
    "# streaming\n",
    "\n",
    "for part in chatbot.stream({\"question\": \"Which model providers offer LLMs?\"}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be740bac-601e-458c-94a3-49163af5f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kernel",
   "language": "python",
   "name": "langchain-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
